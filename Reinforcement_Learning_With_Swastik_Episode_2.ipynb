{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_Learning_With_Swastik_Episode_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOF3kKDEOFfEp9xsHA0S6q/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j2c-90CcClg",
        "colab_type": "code",
        "outputId": "2430d180-b2ca-4421-a857-288cce7c6092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "!pip install opencv-python\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade grpcio\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import argparse\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import gym\n",
        "import gym.spaces\n",
        "import gym.logger as logstat\n",
        "logstat.set_level(gym.logger.INFO)\n",
        "import numpy as np\n",
        "from gym.wrappers import Monitor\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install python-opengl ffmpeg xvfb "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already up-to-date: grpcio in /usr/local/lib/python3.6/dist-packages (1.27.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio) (1.12.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.5)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.10)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKvLidEQdOc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LATENT_VECTOR_SIZE=100\n",
        "DISCR_FILTERS = 64\n",
        "GENER_FILTERS = 64\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9VDAkO0ezTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 64\n",
        "LEARNING_RATE = 0.0001\n",
        "REPORT_EVERY_ITER = 100\n",
        "SAVE_IMAGE_EVERY_ITER=1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqkdqvYdfANa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputWrapper(gym.ObservationWrapper):\n",
        "  ''' \n",
        "  Preprocessing of Input images pipeline\n",
        "  '''\n",
        "  def __init__(self, *args):\n",
        "    super(InputWrapper, self).__init__(*args)\n",
        "    assert isinstance(self.observation_space, gym.spaces.Box)\n",
        "    old_space = self.observation_space\n",
        "    self.observation_space = gym.spaces.Box(self.observation(old_space.low), self.observation(old_space.high), dtype= np.float32)\n",
        "  def observation(self, observation):\n",
        "    #resizing the input image\n",
        "    new_obs = cv2.resize(observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    #transforming the input shape (200, 100, 3) -> (3, 200, 100)\n",
        "    new_obs = np.moveaxis(new_obs, 2, 0)\n",
        "    return new_obs.astype(np.float32)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNG_r8tZh2dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # this pipe converges image into the single number\n",
        "        self.conv_pipe = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 2, out_channels=DISCR_FILTERS * 4,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 4, out_channels=DISCR_FILTERS * 8,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 8, out_channels=1,\n",
        "                      kernel_size=4, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv_pipe(x)\n",
        "        return conv_out.view(-1, 1).squeeze(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrH62z3XjuKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, output_shape):\n",
        "    super(Generator, self).__init__()\n",
        "    self.pipe = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE,out_channels=GENER_FILTERS*8, kernel_size=4, stride=1, padding=0),\n",
        "        nn.BatchNorm2d(GENER_FILTERS*8),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(in_channels=GENER_FILTERS*8, out_channels=GENER_FILTERS*4, kernel_size=4, stride=2, padding=1), \n",
        "        nn.BatchNorm2d(GENER_FILTERS*4),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(in_channels=GENER_FILTERS*4, out_channels=GENER_FILTERS*2, kernel_size=4, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(GENER_FILTERS*2),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(in_channels=GENER_FILTERS*2, out_channels=GENER_FILTERS, kernel_size=4, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(GENER_FILTERS),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0], kernel_size=4, stride=2, padding=1), \n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.pipe(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l6TRRMwkcEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
        "  batch = [e.reset() for e in envs]\n",
        "  env_gen = iter(lambda: random.choice(envs), None)\n",
        "\n",
        "  while True:\n",
        "    e = next(env_gen)\n",
        "    obs, reward, is_done, info = e.step(e.action_space.sample())\n",
        "    if np.mean(obs) > 0.01:\n",
        "      batch.append(obs)\n",
        "    if len(batch) == batch_size:\n",
        "      #normalizing between -1 to 1\n",
        "      batch_np = np.array(batch, dtype=np.float32)* 2.0/255.0 - 1.0\n",
        "      yield torch.tensor(batch_np)\n",
        "      batch.clear()\n",
        "    if is_done:\n",
        "      e.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV5eVpCFVO1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "01582358-0cc5-4d92-81cb-45e61185d7ce"
      },
      "source": [
        "from tqdm import tqdm\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\")\n",
        "    envs = [InputWrapper(gym.make(name)) for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')]\n",
        "    input_shape = envs[0].observation_space.shape\n",
        "\n",
        "    net_discr = Discriminator(input_shape=input_shape).to(device)\n",
        "    net_gener = Generator(output_shape=input_shape).to(device)\n",
        "\n",
        "    objective = nn.BCELoss()\n",
        "    gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "    dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "    \n",
        "\n",
        "    gen_losses = []\n",
        "    dis_losses = []\n",
        "    iter_no = 0\n",
        "\n",
        "    true_labels_v = torch.ones(BATCH_SIZE, dtype=torch.float32, device=device)\n",
        "    fake_labels_v = torch.zeros(BATCH_SIZE, dtype=torch.float32, device=device)\n",
        "\n",
        "    pbar = tqdm(total=7000)\n",
        "\n",
        "    for batch_v in iterate_batches(envs):\n",
        "        gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1).normal_(0, 1).to(device)\n",
        "        batch_v = batch_v.to(device)\n",
        "        gen_output_v = net_gener(gen_input_v)\n",
        "\n",
        "        # train discriminator\n",
        "        dis_optimizer.zero_grad()\n",
        "        dis_output_true_v = net_discr(batch_v)\n",
        "        dis_output_fake_v = net_discr(gen_output_v.detach())\n",
        "        dis_loss = objective(dis_output_true_v, true_labels_v) + objective(dis_output_fake_v, fake_labels_v)\n",
        "        dis_loss.backward()\n",
        "        dis_optimizer.step()\n",
        "        dis_losses.append(dis_loss.item())\n",
        "\n",
        "        # train generator\n",
        "        gen_optimizer.zero_grad()\n",
        "        dis_output_v = net_discr(gen_output_v)\n",
        "        gen_loss_v = objective(dis_output_v, true_labels_v)\n",
        "        gen_loss_v.backward()\n",
        "        gen_optimizer.step()\n",
        "        gen_losses.append(gen_loss_v.item())\n",
        "\n",
        "        iter_no += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "        if iter_no == 7000:\n",
        "          pbar.close()\n",
        "          print(\"Final Result: \")\n",
        "          print(\"Iteration : %d, Discriminator Loss: %f, Generator Loss: %f \" % (iter_no, dis_loss.item(), gen_loss_v.item()))\n",
        "          break;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Making new env: Breakout-v0\n",
            "INFO: Making new env: AirRaid-v0\n",
            "INFO: Making new env: Pong-v0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|â–‹         | 447/7000 [00:29<06:55, 15.76it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}